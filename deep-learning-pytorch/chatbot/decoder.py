import torch
import torch.nn as nn

# TODO: attention layer (Bahdanau or Luong)


# TODO: RNN with attention layer